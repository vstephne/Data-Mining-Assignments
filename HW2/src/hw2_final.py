# -*- coding: utf-8 -*-
"""HW2_Final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V-k_pLFXhIehmfNboyPcRgvwIf1Z7D7w

**CREDIT SCORE PREDICTION**

**Code with one hot encoding**
"""

import pandas as pd

df = pd.read_csv (r'/content/1631544228_021599_credit_train.csv')

df_x = df.iloc[:,:12]
df_y = df.iloc[:,-1]

df_test = pd.read_csv (r'/content/1631544228_0377958_credit_test.csv')

#train
# importing one hot encoder 
from sklearn.preprocessing import OneHotEncoder
# creating one hot encoder object 
onehotencoder = OneHotEncoder()
X = onehotencoder.fit_transform(df_x["F10"].values.reshape(-1,1)).toarray()

dfOneHot = pd.DataFrame(X, columns = ["F10_"+str(int(i)) for i in range(len(df["F10"].unique()))]) 
df_x = pd.concat([df_x, dfOneHot], axis=1)
 
df_x= df_x.drop(['F10'], axis=1) 


#test
# importing one hot encoder 
from sklearn.preprocessing import OneHotEncoder
# creating one hot encoder object 
onehotencoder = OneHotEncoder()
#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object 
X = onehotencoder.fit_transform(df_test["F10"].values.reshape(-1,1)).toarray()
#To add this back into the original dataframe 
dfOneHot = pd.DataFrame(X, columns = ["F10_"+str(int(i)) for i in range(len(df_test["F10"].unique()))]) 
df_test = pd.concat([df_test, dfOneHot], axis=1)

df_test= df_test.drop(["F10"], axis=1) 


df_x = df_x.drop(columns=["id","F3","F8"])

df_test = df_test.drop(columns=["id","F3","F8"])

# importing one hot encoder 
from sklearn.preprocessing import OneHotEncoder
# creating one hot encoder object 
onehotencoder = OneHotEncoder()
#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object 
X = onehotencoder.fit_transform(df_x["F11"].values.reshape(-1,1)).toarray()
#To add this back into the original dataframe 
dfOneHot = pd.DataFrame(X, columns = ["F11_"+str(int(i)) for i in range(len(df["F11"].unique()))]) 
df_x = pd.concat([df_x, dfOneHot], axis=1)

df_x= df_x.drop(["F11"], axis=1) 

#test
# importing one hot encoder 
from sklearn.preprocessing import OneHotEncoder
# creating one hot encoder object 
onehotencoder = OneHotEncoder()
#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object 
X = onehotencoder.fit_transform(df_test["F11"].values.reshape(-1,1)).toarray()
#To add this back into the original dataframe 
dfOneHot = pd.DataFrame(X, columns = ["F11_"+str(int(i)) for i in range(len(df_test["F11"].unique()))]) 
df_test = pd.concat([df_test, dfOneHot], axis=1)

df_test= df_test.drop(["F11"], axis=1) 

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=42)

from sklearn.datasets import make_hastie_10_2
from sklearn.ensemble import GradientBoostingClassifier

clf = GradientBoostingClassifier(n_estimators=300, learning_rate=1.0,max_depth=2, random_state=20)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

#for test file
clf.fit(df_x,df_y)
y_pred=clf.predict(df_test)

f=open('./HW2_output_gradient_boosting.txt', 'w') 
f.writelines("%s \n"%i for i in y_pred)
f.close()

"""**Code with label encoder**"""

import pandas as pd

df = pd.read_csv (r'/content/1631544228_021599_credit_train.csv')
df_x = df.iloc[:,:12]
df_y = df.iloc[:,-1]

df_test = pd.read_csv (r'/content/1631544228_0377958_credit_test.csv')

from sklearn.preprocessing import LabelEncoder

label = LabelEncoder()
df_x['F10'] = label.fit_transform(df_x['F10'].astype('str'))
df_x['F11'] = label.fit_transform(df_x['F11'].astype('str'))

df_test['F10'] = label.fit_transform(df_test['F10'].astype('str'))
df_test['F11'] = label.fit_transform(df_test['F11'].astype('str'))
df_x = df_x.drop(columns=["id","F8","F9","F3"])

df_test = df_test.drop(columns=["id","F8","F9","F3"])


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=42)

from sklearn.datasets import make_hastie_10_2
from sklearn.ensemble import GradientBoostingClassifier

clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0,max_depth=2, random_state=1)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

#for test file
clf.fit(df_x,df_y)
y_pred=clf.predict(df_test)

"""**Correlation** """

import numpy as np
import pandas as pd
df_corr = df_x 
df_corr['credit'] = df_y
print(df_corr.corr())

"""**SMOTE Trial**"""

from imblearn.over_sampling import SMOTE
oversample = SMOTE()
X, y = oversample.fit_resample(df_x, df_y)

"""**Random Forest**"""

#Random Forest

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification

#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)
clf = RandomForestClassifier(max_depth=70, random_state=0)

clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**KNN**"""

#KNN

from sklearn.neighbors import KNeighborsClassifier

#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)
clf = KNeighborsClassifier(n_neighbors=29)

clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=1)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Support Vector Machine**"""

#KLinear SVM

from sklearn import svm
from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)
clf = make_pipeline(StandardScaler(),LinearSVC(random_state=1, tol=1e-5))

clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Perceptron**"""

#perceptron

from sklearn.datasets import load_digits
from sklearn.linear_model import Perceptron

clf = Perceptron(tol=1e-0, random_state=0)


clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)

clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Neural Networks**"""

from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(solver='sgd', alpha=1e-0, hidden_layer_sizes=(10, ), random_state=1)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Decision Tree Classifier**"""

from sklearn import tree
clf = tree.DecisionTreeClassifier(max_depth=8)

clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

from sklearn.linear_model import SGDClassifier
clf = SGDClassifier(loss="hinge", penalty="l2", max_iter=70)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import cross_val_score
clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

"""**Ada Boost Classifier**"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=300)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)


from sklearn.metrics import f1_score
print("F1-Score:",f1_score(y_test, y_pred))

from sklearn.metrics import accuracy_score
print("Accuracy:",accuracy_score(y_test, y_pred))

