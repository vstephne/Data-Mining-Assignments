{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_Final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWVMeEkm2chc"
      },
      "source": [
        "**CREDIT SCORE PREDICTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcbgBbNP2kkh"
      },
      "source": [
        "**Code with one hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Piwc07voVoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9da6b0-bcaf-4f4b-9a23-d8d6dc79271a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv (r'/content/1631544228_021599_credit_train.csv')\n",
        "\n",
        "df_x = df.iloc[:,:12]\n",
        "df_y = df.iloc[:,-1]\n",
        "\n",
        "df_test = pd.read_csv (r'/content/1631544228_0377958_credit_test.csv')\n",
        "\n",
        "#train\n",
        "# importing one hot encoder \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating one hot encoder object \n",
        "onehotencoder = OneHotEncoder()\n",
        "X = onehotencoder.fit_transform(df_x[\"F10\"].values.reshape(-1,1)).toarray()\n",
        "\n",
        "dfOneHot = pd.DataFrame(X, columns = [\"F10_\"+str(int(i)) for i in range(len(df[\"F10\"].unique()))]) \n",
        "df_x = pd.concat([df_x, dfOneHot], axis=1)\n",
        " \n",
        "df_x= df_x.drop(['F10'], axis=1) \n",
        "\n",
        "\n",
        "#test\n",
        "# importing one hot encoder \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating one hot encoder object \n",
        "onehotencoder = OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df_test[\"F10\"].values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"F10_\"+str(int(i)) for i in range(len(df_test[\"F10\"].unique()))]) \n",
        "df_test = pd.concat([df_test, dfOneHot], axis=1)\n",
        "\n",
        "df_test= df_test.drop([\"F10\"], axis=1) \n",
        "\n",
        "\n",
        "df_x = df_x.drop(columns=[\"id\",\"F3\",\"F8\"])\n",
        "\n",
        "df_test = df_test.drop(columns=[\"id\",\"F3\",\"F8\"])\n",
        "\n",
        "# importing one hot encoder \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating one hot encoder object \n",
        "onehotencoder = OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df_x[\"F11\"].values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"F11_\"+str(int(i)) for i in range(len(df[\"F11\"].unique()))]) \n",
        "df_x = pd.concat([df_x, dfOneHot], axis=1)\n",
        "\n",
        "df_x= df_x.drop([\"F11\"], axis=1) \n",
        "\n",
        "#test\n",
        "# importing one hot encoder \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating one hot encoder object \n",
        "onehotencoder = OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df_test[\"F11\"].values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"F11_\"+str(int(i)) for i in range(len(df_test[\"F11\"].unique()))]) \n",
        "df_test = pd.concat([df_test, dfOneHot], axis=1)\n",
        "\n",
        "df_test= df_test.drop([\"F11\"], axis=1) \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=42)\n",
        "\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf = GradientBoostingClassifier(n_estimators=300, learning_rate=1.0,max_depth=2, random_state=20)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "#for test file\n",
        "clf.fit(df_x,df_y)\n",
        "y_pred=clf.predict(df_test)\n",
        "\n",
        "f=open('./HW2_output_gradient_boosting.txt', 'w') \n",
        "f.writelines(\"%s \\n\"%i for i in y_pred)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.6913210773834972\n",
            "Accuracy: 0.8656244183882374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ4IWZbZ2pKN"
      },
      "source": [
        "**Code with label encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlX30DOMpwJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a39a90-8927-4834-8bdc-1827d4f81a1b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv (r'/content/1631544228_021599_credit_train.csv')\n",
        "df_x = df.iloc[:,:12]\n",
        "df_y = df.iloc[:,-1]\n",
        "\n",
        "df_test = pd.read_csv (r'/content/1631544228_0377958_credit_test.csv')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label = LabelEncoder()\n",
        "df_x['F10'] = label.fit_transform(df_x['F10'].astype('str'))\n",
        "df_x['F11'] = label.fit_transform(df_x['F11'].astype('str'))\n",
        "\n",
        "df_test['F10'] = label.fit_transform(df_test['F10'].astype('str'))\n",
        "df_test['F11'] = label.fit_transform(df_test['F11'].astype('str'))\n",
        "df_x = df_x.drop(columns=[\"id\",\"F8\",\"F9\",\"F3\"])\n",
        "\n",
        "df_test = df_test.drop(columns=[\"id\",\"F8\",\"F9\",\"F3\"])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=42)\n",
        "\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0,max_depth=2, random_state=1)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "#for test file\n",
        "clf.fit(df_x,df_y)\n",
        "y_pred=clf.predict(df_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.6907127429805615\n",
            "Accuracy: 0.8667411129722687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts8fs8IJ8LFO"
      },
      "source": [
        "**Correlation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVIZsMZ0oYzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7f8fc7-442a-462a-e9ea-3202fbfa82f0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_corr = df_x \n",
        "df_corr['credit'] = df_y\n",
        "print(df_corr.corr())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              F1        F2        F3  ...     F11_0     F11_1    credit\n",
            "F1      1.000000  0.148123 -0.094153  ... -0.012280  0.012280  0.335154\n",
            "F2      0.148123  1.000000 -0.248974  ... -0.229309  0.229309  0.229689\n",
            "F3     -0.094153 -0.248974  1.000000  ...  0.582454 -0.582454 -0.250918\n",
            "F4      0.109697  0.080383 -0.075607  ... -0.080296  0.080296  0.075468\n",
            "F5      0.122630  0.078409 -0.057919  ... -0.048480  0.048480  0.223329\n",
            "F6      0.079923  0.054256 -0.061062  ... -0.045567  0.045567  0.150526\n",
            "F7     -0.069304 -0.190519  0.185451  ...  0.129314 -0.129314 -0.199307\n",
            "F8      0.052085  0.138962 -0.090461  ... -0.095981  0.095981  0.051604\n",
            "F9      0.359153  0.055510 -0.010876  ...  0.027356 -0.027356  0.079317\n",
            "F10_0  -0.029345 -0.003096  0.025190  ...  0.010820 -0.010820 -0.028721\n",
            "F10_1   0.062091 -0.004564  0.011226  ...  0.000856 -0.000856  0.010543\n",
            "F10_2  -0.075272 -0.053153  0.138081  ...  0.115604 -0.115604 -0.089089\n",
            "F10_3  -0.044133 -0.007188  0.015998  ...  0.013906 -0.013906 -0.031830\n",
            "F10_4   0.051353  0.049345 -0.131913  ... -0.103486  0.103486  0.085224\n",
            "F11_0  -0.012280 -0.229309  0.582454  ...  1.000000 -1.000000 -0.215980\n",
            "F11_1   0.012280  0.229309 -0.582454  ... -1.000000  1.000000  0.215980\n",
            "credit  0.335154  0.229689 -0.250918  ... -0.215980  0.215980  1.000000\n",
            "\n",
            "[17 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS6gp5FR8e0P"
      },
      "source": [
        "**SMOTE Trial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVHlniqcofhB"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(df_x, df_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z6nt4Zw8hN8"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf0aoZsGpDC-"
      },
      "source": [
        "#Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
        "clf = RandomForestClassifier(max_depth=70, random_state=0)\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGok2sNHCjN"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDyF3yuWpHDg"
      },
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
        "clf = KNeighborsClassifier(n_neighbors=29)\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-dFx_qBHKPX"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNLQ2U_YpILn"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(random_state=1)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fioHwWm0HMdW"
      },
      "source": [
        "**Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15iu37x5pOId"
      },
      "source": [
        "#KLinear SVM\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#df_train, df_test = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
        "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=1, tol=1e-5))\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RADp1yy_xDp"
      },
      "source": [
        "**Perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC23lzEQpSCz"
      },
      "source": [
        "#perceptron\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "clf = Perceptron(tol=1e-0, random_state=0)\n",
        "\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOwGcwc_4Zz"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbIv-J9kpa39"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0)\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjYB5-eR_8Pp"
      },
      "source": [
        "**Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOaJS8AkpdFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d73d80d-fb0a-4a1c-d142-d5dc07353636"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='sgd', alpha=1e-0, hidden_layer_sizes=(10, ), random_state=1)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.6268564356435644\n",
            "Accuracy: 0.7755443886097152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2EtSo3TtOFT"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPUT5Gdzpeh2"
      },
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier(max_depth=8)\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xFX2bpZpi05"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=70)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndF69zH9pmfd"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ0AZnOEsD9j",
        "outputId": "31d4a611-7a1f-4028-bf2e-5db6b398962a"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.6249464209172739\n",
            "Accuracy: 0.8371487064954402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZoBNglUtIDC"
      },
      "source": [
        "**Ada Boost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK6GQuknsPP0",
        "outputId": "9e2fa1af-4ea9-4f4e-e090-6d2260b7d14c"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=300)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-Score:\",f1_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.678996036988111\n",
            "Accuracy: 0.864321608040201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlYG0I4ds7Ls"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}